{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Cluster Ensembles to Identify Psychiatric Patient Subgroups\n",
    "This is the code that belongs to the paper that has been submitted for publication under the title above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from hopkins_statistic import hopkins\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading and preprocessing Youth Self Report (YSR) data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load and preprocess YSR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ysr = pd.read_csv(os.path.join(data_path, 'ysr_source.csv'), sep=\";\")\n",
    "\n",
    "# Parse date\n",
    "ysr['DATUM'] = pd.to_datetime(ysr['DATUM'], format='%Y-%m-%d')\n",
    "\n",
    "# The Ysr contains 112 items, item 56h is a free text item and is dismissed\n",
    "ysr_items = ysr.columns[[c.startswith(\"v\") for c in ysr.columns]][:120]\n",
    "ysr_items = ysr_items.drop(['v56h_Andere_problemen_schrijf_op'], 1)\n",
    "\n",
    "# Only retain YSRs with at most five percent missing values (five percent of 112 items = minimum of six)\n",
    "ysr = ysr[ysr[ysr_items].isnull().sum(1) <= 6]\n",
    "\n",
    "# Add id\n",
    "ysr['id_ysr'] = np.arange(len(ysr)) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preprocess items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preprocess each item\n",
    "for item in ysr_items:\n",
    "    \n",
    "    # Map item responses to numeric responses\n",
    "    ysr[item] = ysr[item].map({'Helemaal niet (voor zover u/je weet)' : 0,\n",
    "                               'Een beetje of soms' : 1,\n",
    "                               'Duidelijk of vaak' : 2\n",
    "                              })\n",
    "    \n",
    "    # If value is missing, imputed with median value\n",
    "    ysr[item] = ysr[item].fillna(ysr[item].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compute outcome scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Relevant items for each of the eight outcome scales. (From: http://www.aseba.org/forms/ysrprofile.pdf)\n",
    "scales_map = {'(1) Anxious depressed'        : [14,29,30,31,32,33,35,45,50,52,71,91,112],\n",
    "              '(2) Withdrawn depressed'      : [5,42,65,69,75,102,103,111],\n",
    "              '(3) Somatic complaints'       : [47,51,54,'56a','56b','56c','56d','56e','56f','56g'],\n",
    "              '(4) Social problems'          : [11,12,25,27,34,36,38,48,62,64,79],\n",
    "              '(5) Thought problems'         : [9,18,40,46,58,66,70,76,83,84,85,100],\n",
    "              '(6) Attention problems'       : [1,4,8,10,13,17,41,61,78],\n",
    "              '(7) Rule breaking behaviour'  : [2,26,28,39,43,63,67,72,81,82,90,96,99,101,105],\n",
    "              '(8) Aggressive behaviour'     : [3,16,19,20,21,22,23,37,57,68,86,87,89,94,95,97,104]}\n",
    "\n",
    "# Find correct column name related to item number\n",
    "def find_column(item_no):\n",
    "    return [i for i in ysr_items if i.startswith(\"v{}_\".format(item_no))][0]\n",
    "\n",
    "# Sum scales\n",
    "for scale in scales_map.keys():\n",
    "    ysr[scale] = ysr[[find_column(item_no) for item_no in scales_map[scale]]].sum(1)\n",
    "\n",
    "# List of outcome scales names for subsetting\n",
    "ysr_outcome_scales = list(scales_map.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Finalize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all ysr with a total score of 0\n",
    "ysr = ysr[ysr[ysr_outcome_scales].sum(1) > 0]\n",
    "\n",
    "# Take first if multiple are present\n",
    "ysr = ysr.sort_values(\"DATUM\")\n",
    "ysr = ysr.groupby(\"Patient_id\").first().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compute hopkins statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_repeats = 10\n",
    "h = 0\n",
    "\n",
    "for i in range(no_repeats):\n",
    "    h += hopkins(ysr[ysr_outcome_scales])\n",
    "\n",
    "print(\"Hopkins statistic = {:.3f}\".format(h/no_repeats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cluster ensemble modeling: R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster Ensemble modeling is more easily done in R, using the packages NbClust and Dice. We therefore write the YSR file so that we can open it in R. After R script *cluster_ensemble_modeling.r* is applied to the dataset, it writes the clusters which we load in the next step. Although we could potentially integrate Python and R using interface packages, this is not worth the trouble in this case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write to csv\n",
    "ysr[ysr_outcome_scales].to_csv(os.path.join(data_path,  'ysr.csv'), index=False, sep=\";\")\n",
    "\n",
    "##########################\n",
    "### R SCRIPTS RUN HERE ###\n",
    "##########################\n",
    "\n",
    "# The output of the R script is a column with YSR observations as rows, and columns\n",
    "#    - PCA-1              : x-coordinate of the PCA \n",
    "#    - PCA-2              : y-coordinate of the PCA\n",
    "#    - partition_km       : partioning of the kmeans algorithm\n",
    "#    - partition_gmm      :                   gaussian mixture model algorithm\n",
    "#    - partition_ap       :                   affinity propagation algorithm\n",
    "#    - partition_ensemble :                   cluster ensemble\n",
    "\n",
    "c_result = pd.read_csv(os.path.join(data_path, 'clusters_result.csv'), sep=\";\").reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We relabel clusters in order to compare them, based on orientation of center of mass relative to the origin\n",
    "for column_name in ['partition_km', 'partition_gmm', 'partition_ap', 'partition_ensemble']:\n",
    "    l = list(c_result.groupby(column_name).apply(lambda x : np.arctan2(np.mean(x['PCA-1']), np.mean(x['PCA-2']))).sort_values(ascending=False).index)\n",
    "    mapping = {k:v for k,v in zip(l, list(np.arange(3)+1))}\n",
    "    c_result[column_name] = c_result[column_name].map(mapping)\n",
    "\n",
    "# Create an additional dataframe which allows integrating the clusters to YSR ids\n",
    "ysr_clusters = pd.concat([ysr[['DATUM', 'id_ysr', 'Patient_id']], c_result[['partition_ensemble']]], axis=1)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PCA plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-white')\n",
    "fig, ax = plt.subplots(1, 4, sharex='col', sharey='row', figsize=(12, 3), dpi=350, squeeze=True)\n",
    "\n",
    "sns.scatterplot(x='PCA-1', \n",
    "                y='PCA-2', \n",
    "                data=c_result,\n",
    "                palette=sns.color_palette('hls', 3),\n",
    "                style='partition_km',\n",
    "                hue='partition_km',\n",
    "                legend=False,\n",
    "                ax=ax[0])\n",
    "\n",
    "sns.scatterplot(x='PCA-1', \n",
    "                y='PCA-2', \n",
    "                data=c_result,\n",
    "                palette=sns.color_palette('hls', 3),\n",
    "                style='partition_gmm',\n",
    "                hue='partition_gmm',\n",
    "                legend=False,\n",
    "                ax=ax[1])\n",
    "\n",
    "sns.scatterplot(x='PCA-1', \n",
    "                y='PCA-2', \n",
    "                data=c_result,\n",
    "                palette=sns.color_palette('hls', 3),\n",
    "                style='partition_ap',\n",
    "                hue='partition_ap',\n",
    "                legend=False,\n",
    "                ax=ax[2])\n",
    "\n",
    "sns.scatterplot(x='PCA-1', \n",
    "                y='PCA-2', \n",
    "                data=c_result,\n",
    "                palette=sns.color_palette('hls', 3),\n",
    "                style='partition_ensemble',\n",
    "                hue='partition_ensemble',\n",
    "                legend=False,\n",
    "                ax=ax[3])\n",
    "\n",
    "ax[0].set_title(\"(a) K-means\")\n",
    "ax[1].set_title(\"(b) Gaussian Mixture Model\")\n",
    "ax[2].set_title(\"(c) Affinity Propagation\")\n",
    "ax[3].set_title(\"(d) Cluster Ensemble\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bar Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Concatenate YSR outcome scales and Cluster Ensemble labels\n",
    "ysr_clustered = pd.concat([ysr[ysr_outcome_scales], c_result['partition_ensemble']], axis=1)\n",
    "\n",
    "# Compute median value for each cluster\n",
    "ysr_clustered = ysr_clustered.groupby(\"partition_ensemble\").median().transpose().reset_index()\n",
    "\n",
    "# Reshape to long format for seaborn plot\n",
    "ysr_clustered = pd.melt(ysr_clustered, id_vars='index')\n",
    "\n",
    "# Descriptive names for legend\n",
    "ysr_clustered['partition_ensemble'] = ysr_clustered['partition_ensemble'].map({1 : 'Cluster 1', \n",
    "                                                                               2 : 'Cluster 2', \n",
    "                                                                               3 : 'Cluster 3'})\n",
    "# Add figure as bar plot\n",
    "fig = sns.catplot(x='index', \n",
    "                  y='value', \n",
    "                  kind='bar',\n",
    "                  data=ysr_clustered, \n",
    "                  hue='partition_ensemble', \n",
    "                  palette=sns.color_palette('hls', 3),\n",
    "                  aspect=2.5,\n",
    "                  legend=False,\n",
    "                 )\n",
    "\n",
    "# Add legend, x and y labels, rotate x \n",
    "plt.legend(loc='upper right', fontsize=20)\n",
    "plt.xlabel(\"Outcome scale\", fontsize=20)\n",
    "plt.ylabel(\"Median value\", fontsize=20)\n",
    "plt.xticks(rotation=70, fontsize=18)\n",
    "\n",
    "fig.savefig('outcome_scales_barplot.png', dpi=350)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Integrate DSM diagnosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Dutch healthcare, DSM diagnosis is registered in a administrative construct called a DBC, which also includes some other relevant variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read file\n",
    "dbc = pd.read_csv(os.path.join(data_path, 'dbc.csv'), sep=\";\")\n",
    "\n",
    "# Parse dates\n",
    "dbc['DiagnoseDatum'] = pd.to_datetime(dbc['DiagnoseDatum'], format='%Y-%m-%d')\n",
    "dbc['Startdatum'] = pd.to_datetime(dbc['Startdatum'], format='%Y-%m-%d')\n",
    "dbc['Einddatum'] = pd.to_datetime(dbc['Einddatum'], format='%Y-%m-%d')\n",
    "\n",
    "# Add length \n",
    "dbc['length'] = (dbc['Einddatum'] - dbc['Startdatum']) / pd.Timedelta('1 day')\n",
    "\n",
    "# Add id\n",
    "dbc['id_dbc'] = np.arange(len(dbc)) + 1\n",
    "\n",
    "# Only filled in date and diagnosis\n",
    "dbc = dbc[dbc['DiagnoseDatum'].notnull()]\n",
    "dbc = dbc[dbc['diagnosegroep1'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Merge\n",
    "dbc_merged = dbc.merge(ysr_clusters)\n",
    "\n",
    "# Select within 12 weeks\n",
    "dbc_merged['daydiff'] = abs((dbc_merged['DATUM'] - dbc_merged['DiagnoseDatum']) / pd.Timedelta('1 day'))\n",
    "dbc_diagnose = dbc_merged[dbc_merged['daydiff'] <= (12 * 7)]\n",
    "\n",
    "# Select first if multiple\n",
    "dbc_diagnose = dbc_diagnose.sort_values('daydiff')\n",
    "dbc_diagnose = dbc_diagnose.groupby(\"id_ysr\").first().reset_index()\n",
    "\n",
    "# Crosstab\n",
    "pd.crosstab(dbc_diagnose['partition_ensemble'], dbc_diagnose['diagnosegroep1omschrijving']).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Integrate clinical notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Notes are already integrated in a clinical data warehouse\n",
    "notes = pd.read_csv(os.path.join(data_path, 'notes.csv'), sep=\";\")\n",
    "\n",
    "# Concatenate if multiple notes exist\n",
    "notes = notes.groupby(\"id_ysr\")['Text'].apply(lambda x : \"\\n\".join(x)).reset_index()\n",
    "\n",
    "# Merge cluster labels\n",
    "ysr_notes = notes.merge(ysr_clusters, how='left', left_on='id_ysr', right_on='id_ysr').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vectorize to bag of words\n",
    "count_vect = CountVectorizer(ngram_range=(1,1), max_features=1000, binary=False)\n",
    "bag_of_words = count_vect.fit_transform(ysr_notes['Text'])\n",
    "bow_df = pd.DataFrame(bag_of_words.toarray(), columns=[x for x in count_vect.get_feature_names()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outcome_dict = {'column' : bow_df.columns}\n",
    "\n",
    "# Iterate over clusters numbers\n",
    "for cluster_id in sorted(ysr_notes['partition_ensemble'].unique()):\n",
    "\n",
    "    # Outcome is defined as cluster label\n",
    "    y = (ysr_notes['partition_ensemble'] == cluster_id)\n",
    "    \n",
    "    # Save spearman correlations\n",
    "    rhos = []\n",
    "    \n",
    "    # Compute correlations\n",
    "    for c in bow_df.columns:\n",
    "        rhos.append(stats.spearmanr(bow_df[c], b=y).correlation)\n",
    "    \n",
    "    # Add to outcome dictionary\n",
    "    outcome_dict[cluster_id] = rhos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(outcome_dict).sort_values(1.0, ascending=False)\n",
    "pd.DataFrame(outcome_dict).sort_values(2.0, ascending=False)\n",
    "pd.DataFrame(outcome_dict).sort_values(3.0, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Clinically relevant variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Show differences among clusters\n",
    "These variables are again extracted from the DBC construct, which registers such variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge\n",
    "dbc_merged = dbc.merge(ysr_clusters)\n",
    "\n",
    "# Select only relevant \n",
    "dbc_merged = dbc_merged[(dbc_merged['DATUM'] >= dbc_merged['Startdatum']) & (dbc_merged['DATUM'] <= dbc_merged['Einddatum'])]\n",
    "\n",
    "# Select first if multiple\n",
    "dbc_merged = dbc_merged.sort_values('Einddatum', ascending=False)\n",
    "dbc_merged = dbc_merged.groupby(\"id_ysr\").first().reset_index()\n",
    "\n",
    "# Measured outcome variables\n",
    "outcome_vars = ['zorgvraagzwaarte', 'gafstart_ondergrens', 'gafeind_ondergrens', 'length']\n",
    "                # zorgvraagzwaarte = burden of disease indicator\n",
    "\n",
    "# Show differences\n",
    "dbc_merged.groupby(\"partition_ensemble\")[outcome_vars].mean().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Statistical testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{:25s} {:25s}\".format(\"Variabele\", \"P-value\"))\n",
    "print(\"{:25s} {:25s}\".format(\"=========\", \"========\"))\n",
    "\n",
    "for v in outcome_vars:\n",
    "    x1 = dbc_merged[dbc_merged['partition_ensemble'] == 1][v]\n",
    "    x2 = dbc_merged[dbc_merged['partition_ensemble'] == 2][v]\n",
    "    x3 = dbc_merged[dbc_merged['partition_ensemble'] == 3][v]\n",
    "    \n",
    "    x1 = x1[x1.notnull()]\n",
    "    x2 = x2[x2.notnull()]\n",
    "    x3 = x3[x3.notnull()]\n",
    "    \n",
    "    s, p = stats.kruskal(x1, x2, x3)\n",
    "    \n",
    "    print(\"{:25s} {:.3f}\".format(v, p))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
